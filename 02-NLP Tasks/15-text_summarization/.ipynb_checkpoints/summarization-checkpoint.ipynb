{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于T5的文本摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:03:34.493020Z",
     "iopub.status.busy": "2024-07-23T08:03:34.492684Z",
     "iopub.status.idle": "2024-07-23T08:03:34.495787Z",
     "shell.execute_reply": "2024-07-23T08:03:34.495275Z",
     "shell.execute_reply.started": "2024-07-23T08:03:34.493001Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T07:39:46.966868Z",
     "iopub.status.busy": "2024-07-23T07:39:46.966295Z",
     "iopub.status.idle": "2024-07-23T07:39:46.981129Z",
     "shell.execute_reply": "2024-07-23T07:39:46.980540Z",
     "shell.execute_reply.started": "2024-07-23T07:39:46.966844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.load_from_disk(\"./nlpcc_2017/\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T07:39:50.622783Z",
     "iopub.status.busy": "2024-07-23T07:39:50.622407Z",
     "iopub.status.idle": "2024-07-23T07:39:50.639263Z",
     "shell.execute_reply": "2024-07-23T07:39:50.638789Z",
     "shell.execute_reply.started": "2024-07-23T07:39:50.622763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 4900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.train_test_split(100, seed=42)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T07:42:03.085060Z",
     "iopub.status.busy": "2024-07-23T07:42:03.084603Z",
     "iopub.status.idle": "2024-07-23T07:42:03.098993Z",
     "shell.execute_reply": "2024-07-23T07:42:03.098259Z",
     "shell.execute_reply.started": "2024-07-23T07:42:03.085024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '组图:黑河边防军人零下30℃户外训练,冰霜沾满眉毛和睫毛,防寒服上满是冰霜。',\n",
       " 'content': '中国军网2014-12-1709:08:0412月16日,黑龙江省军区驻黑河某边防团机动步兵连官兵,冒着-30℃严寒气温进行体能训练,挑战极寒,锻造钢筋铁骨。该连素有“世界冠军的摇篮”之称,曾有5人24人次登上世界军事五项冠军的领奖台。(魏建顺摄)黑龙江省军区驻黑河某边防团机动步兵连官兵冒着-30℃严寒气温进行体能训练驻黑河某边防团机动步兵连官兵严寒中户外训练,防寒服上满是冰霜驻黑河某边防团机动步兵连官兵严寒中户外训练,防寒服上满是冰霜官兵睫毛上都被冻上了冰霜官兵们睫毛上都被冻上了冰霜驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"langboat/mengzi-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:24.356238Z",
     "iopub.status.busy": "2024-07-23T08:04:24.355903Z",
     "iopub.status.idle": "2024-07-23T08:04:24.359474Z",
     "shell.execute_reply": "2024-07-23T08:04:24.359021Z",
     "shell.execute_reply.started": "2024-07-23T08:04:24.356217Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/.cache/modelscope/langboat/mengzi-t5-base'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:29.534025Z",
     "iopub.status.busy": "2024-07-23T08:04:29.533685Z",
     "iopub.status.idle": "2024-07-23T08:04:29.743790Z",
     "shell.execute_reply": "2024-07-23T08:04:29.743241Z",
     "shell.execute_reply.started": "2024-07-23T08:04:29.534007Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:48.254938Z",
     "iopub.status.busy": "2024-07-23T08:04:48.254580Z",
     "iopub.status.idle": "2024-07-23T08:04:48.258273Z",
     "shell.execute_reply": "2024-07-23T08:04:48.257798Z",
     "shell.execute_reply.started": "2024-07-23T08:04:48.254919Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(exmaples):\n",
    "    contents = [\"摘要生成: \\n\" + e for e in exmaples[\"content\"]]\n",
    "    inputs = tokenizer(contents, max_length=384, truncation=True)\n",
    "    labels = tokenizer(text_target=exmaples[\"title\"], max_length=64, truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:51.127094Z",
     "iopub.status.busy": "2024-07-23T08:04:51.126768Z",
     "iopub.status.idle": "2024-07-23T08:04:51.848060Z",
     "shell.execute_reply": "2024-07-23T08:04:51.847608Z",
     "shell.execute_reply.started": "2024-07-23T08:04:51.127075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, batched=True)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:54.054565Z",
     "iopub.status.busy": "2024-07-23T08:04:54.054220Z",
     "iopub.status.idle": "2024-07-23T08:04:54.060048Z",
     "shell.execute_reply": "2024-07-23T08:04:54.059512Z",
     "shell.execute_reply.started": "2024-07-23T08:04:54.054544Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'摘要生成: 中国军网2014-12-1709:08:0412月16日,黑龙江省军区驻黑河某边防团机动步兵连官兵,冒着-30°C严寒气温进行体能训练,挑战极寒,锻造钢筋铁骨。该连素有“世界冠军的摇篮”之称,曾有5人24人次登上世界军事五项冠军的领奖台。(魏建顺摄)黑龙江省军区驻黑河某边防团机动步兵连官兵冒着-30°C严寒气温进行体能训练驻黑河某边防团机动步兵连官兵严寒中户外训练,防寒服上满是冰霜驻黑河某边防团机动步兵连官兵严寒中户外训练,防寒服上满是冰霜官兵睫毛上都被冻上了冰霜官兵们睫毛上都被冻上了冰霜驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练驻黑河某边防团机动步兵连官兵严寒中进行户外体能训练</s>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T08:04:55.671979Z",
     "iopub.status.busy": "2024-07-23T08:04:55.671658Z",
     "iopub.status.idle": "2024-07-23T08:04:55.676038Z",
     "shell.execute_reply": "2024-07-23T08:04:55.675596Z",
     "shell.execute_reply.started": "2024-07-23T08:04:55.671960Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'组图:黑河边防军人零下30°C户外训练,冰霜沾满眉毛和睫毛,防寒服上满是冰霜。</s>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:06:05.295036Z",
     "iopub.status.busy": "2024-07-23T08:06:05.294702Z",
     "iopub.status.idle": "2024-07-23T08:06:05.299059Z",
     "shell.execute_reply": "2024-07-23T08:06:05.298415Z",
     "shell.execute_reply.started": "2024-07-23T08:06:05.295015Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 760, 313, 13, 409, 16287, 1139, 7694, 1512, 64, 100, 10788, 722, 5968, 1332, 3, 1301, 3883, 5671, 586, 13902, 9, 13424, 3, 1139, 1342, 1163, 23, 586, 11, 1301, 3883, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_ds[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:05:40.630572Z",
     "iopub.status.busy": "2024-07-23T08:05:40.630198Z",
     "iopub.status.idle": "2024-07-23T08:05:52.249399Z",
     "shell.execute_reply": "2024-07-23T08:05:52.248648Z",
     "shell.execute_reply.started": "2024-07-23T08:05:40.630551Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 创建评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:33:59.164578Z",
     "iopub.status.busy": "2024-07-23T08:33:59.164261Z",
     "iopub.status.idle": "2024-07-23T08:33:59.172537Z",
     "shell.execute_reply": "2024-07-23T08:33:59.170221Z",
     "shell.execute_reply.started": "2024-07-23T08:33:59.164560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge_chinese import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def compute_metric(evalPred):\n",
    "    def calculate_bleu_scores(candidate, references):\n",
    "        candidate = list(candidate.split(\" \"))\n",
    "        reference = [list(references.split(\" \"))]\n",
    "        weights_list = [\n",
    "            (1, 0, 0, 0),   # BLEU-1\n",
    "            (0.5, 0.5, 0, 0),   # BLEU-2\n",
    "            (1/3, 1/3, 1/3, 0),   # BLEU-3\n",
    "            (0.25, 0.25, 0.25, 0.25) # BLEU-4\n",
    "        ]\n",
    "\n",
    "        bleu_scores = []\n",
    "        for weights in weights_list:\n",
    "            # print(sentence_bleu(reference, candidate, weights=weights))\n",
    "            score = sentence_bleu(reference, candidate, weights=weights)\n",
    "            bleu_scores.append(score)\n",
    "        return bleu_scores\n",
    "    predictions, labels = evalPred\n",
    "    decode_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(l) for l in decode_labels]\n",
    "    rouge_scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    bleu_scores_batch = np.mean(np.array([calculate_bleu_scores(cand, refs) for cand, refs in zip(decode_preds, decode_labels)]), axis=0)\n",
    "    return {\n",
    "        \"rouge-1\": rouge_scores[\"rouge-1\"][\"f\"],\n",
    "        \"rouge-2\": rouge_scores[\"rouge-2\"][\"f\"],\n",
    "        \"rouge-l\": rouge_scores[\"rouge-l\"][\"f\"],\n",
    "        \"bleu-l\": bleu_scores_batch[0],\n",
    "        \"bleu-2\": bleu_scores_batch[1],\n",
    "        \"bleu-3\": bleu_scores_batch[2],\n",
    "        \"bleu-4\": bleu_scores_batch[3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:38:47.848432Z",
     "iopub.status.busy": "2024-07-23T08:38:47.848065Z",
     "iopub.status.idle": "2024-07-23T08:38:47.853719Z",
     "shell.execute_reply": "2024-07-23T08:38:47.853324Z",
     "shell.execute_reply.started": "2024-07-23T08:38:47.848413Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['这 是 一 份 行 动 指 南 ， 确 保 军 队 始 终 服 从 党 的 命 令', '确 保 军 队 始 终 服 从 党 的 命 令'] ['这 是 一 份 行 动 指 南 ， 确 保 军 队 永 远 听 从 党 的 指 挥', '确 保 军 队 永 远 听 从 党 的 指 挥']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.6916666666666667,\n",
       "  'p': 0.6726190476190477,\n",
       "  'f': 0.6819105641071784},\n",
       " 'rouge-2': {'r': 0.5772727272727273,\n",
       "  'p': 0.5772727272727273,\n",
       "  'f': 0.5772727222727273},\n",
       " 'rouge-l': {'r': 0.6726190476190477,\n",
       "  'p': 0.6726190476190477,\n",
       "  'f': 0.6726190426190477}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "decode_preds = [\" \".join(p) for p in [\"这是一份行动指南，确保军队始终服从党的命令\", \"确保军队始终服从党的命令\"]]\n",
    "decode_labels = [\" \".join(l) for l in [\"这是一份行动指南，确保军队永远听从党的指挥\", \"确保军队永远听从党的指挥\"]]\n",
    "print(decode_preds, decode_labels)\n",
    "scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T08:48:22.686607Z",
     "iopub.status.busy": "2024-07-23T08:48:22.686283Z",
     "iopub.status.idle": "2024-07-23T08:48:22.693327Z",
     "shell.execute_reply": "2024-07-23T08:48:22.692916Z",
     "shell.execute_reply.started": "2024-07-23T08:48:22.686590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu-1': 0.6726190476190477,\n",
       " 'bleu-2': 0.6226126969423293,\n",
       " 'bleu-3': 0.5629274739822036,\n",
       " 'bleu-4': 0.4821654810102169}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "# 定义一个函数来计算所有四个BLEU分数\n",
    "\n",
    "\n",
    "\n",
    "# 使用一个列表推导式来计算batch中每个候选句子的BLEU分数\n",
    "bleu_scores_batch = np.mean(np.array([calculate_bleu_scores(cand, refs) for cand, refs in zip(decode_preds, decode_labels)]), axis=0)\n",
    "bleu_dict = {f'bleu-{i+1}': score for i, score in enumerate(bleu_scores_batch)}\n",
    "bleu_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"rouge-l\",\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 创建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"摘要生成:\\n\" + ds[\"test\"][-1][\"content\"], max_length=64, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"test\"][-1][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

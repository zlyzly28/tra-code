{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于T5的文本摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers rouge-score nltk rouge_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:34:35.805753Z",
     "iopub.status.busy": "2024-07-23T10:34:35.805401Z",
     "iopub.status.idle": "2024-07-23T10:34:35.964592Z",
     "shell.execute_reply": "2024-07-23T10:34:35.963968Z",
     "shell.execute_reply.started": "2024-07-23T10:34:35.805732Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidVersion",
     "evalue": "Invalid version: '0.10.1,<0.11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidVersion\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/__init__.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     45\u001b[0m     _BaseLazyModule,\n\u001b[1;32m     46\u001b[0m     is_flax_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     is_torch_available,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/dependency_versions_check.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/utils/versions.py:94\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" require_version wrapper which emits a core-specific hint on failure \"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git master\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/utils/versions.py:85\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pkg_resources\u001b[38;5;241m.\u001b[39mDistributionNotFound(requirement, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis application\u001b[39m\u001b[38;5;124m\"\u001b[39m, hint])\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# check that the right version is installed if version number was provided\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), \u001b[43mversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pkg_resources\u001b[38;5;241m.\u001b[39mVersionConflict(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/packaging/version.py:52\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(version)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/packaging/version.py:197\u001b[0m, in \u001b[0;36mVersion.__init__\u001b[0;34m(self, version)\u001b[0m\n\u001b[1;32m    195\u001b[0m match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_regex\u001b[38;5;241m.\u001b[39msearch(version)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid version: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Store the parsed out pieces of the version\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version \u001b[38;5;241m=\u001b[39m _Version(\n\u001b[1;32m    201\u001b[0m     epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    202\u001b[0m     release\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelease\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     local\u001b[38;5;241m=\u001b[39m_parse_local_version(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    209\u001b[0m )\n",
      "\u001b[0;31mInvalidVersion\u001b[0m: Invalid version: '0.10.1,<0.11'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:03.634378Z",
     "iopub.status.busy": "2024-07-23T10:20:03.634011Z",
     "iopub.status.idle": "2024-07-23T10:20:03.641629Z",
     "shell.execute_reply": "2024-07-23T10:20:03.641203Z",
     "shell.execute_reply.started": "2024-07-23T10:20:03.634355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.load_from_disk(\"./nlpcc_2017/\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:05.513205Z",
     "iopub.status.busy": "2024-07-23T10:20:05.512859Z",
     "iopub.status.idle": "2024-07-23T10:20:05.519117Z",
     "shell.execute_reply": "2024-07-23T10:20:05.518691Z",
     "shell.execute_reply.started": "2024-07-23T10:20:05.513184Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /mnt/workspace/tra-code/02-NLP Tasks/15-text_summarization/nlpcc_2017/cache-f88b03791a18aede.arrow and /mnt/workspace/tra-code/02-NLP Tasks/15-text_summarization/nlpcc_2017/cache-6b0d5568bb085c36.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.train_test_split(200, seed=42)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:08.096960Z",
     "iopub.status.busy": "2024-07-23T10:20:08.096649Z",
     "iopub.status.idle": "2024-07-23T10:20:08.100639Z",
     "shell.execute_reply": "2024-07-23T10:20:08.100202Z",
     "shell.execute_reply.started": "2024-07-23T10:20:08.096943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '郴州市发布雷电橙色预警:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受...',\n",
       " 'content': '发布日期:2015-03-3007:55:33郴州市气象台3月30日7时52分发布雷电橙色预警信号:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受雷电活动影响,并将持续,出现雷电灾害事故的可能性比较大,请注意防范。图例标准防御指南2小时内发生雷电活动的可能性很大,或者已经受雷电活动影响,且可能持续,出现雷电灾害事故的可能性比较大。1、政府及相关部门按照职责落实防雷应急措施;2、人员应当留在室内,并关好门窗;3、户外人员应当躲入有防雷设施的建筑物或者汽车内;4、切断危险电源,不要在树下、电杆下、塔吊下避雨;5、在空旷场地不要打伞,不要把农具、羽毛球拍、高尔夫球杆等扛在肩上。'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:13.093332Z",
     "iopub.status.busy": "2024-07-23T10:20:13.092989Z",
     "iopub.status.idle": "2024-07-23T10:20:14.026369Z",
     "shell.execute_reply": "2024-07-23T10:20:14.025826Z",
     "shell.execute_reply.started": "2024-07-23T10:20:13.093312Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 18:20:13,115 - modelscope - INFO - PyTorch version 2.0.1+cpu Found.\n",
      "2024-07-23 18:20:13,117 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2024-07-23 18:20:13,118 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2024-07-23 18:20:13,141 - modelscope - INFO - Loading done! Current index file version is 1.9.5, with md5 79827826d04c54fc06982662c5095533 and a total number of 945 components indexed\n",
      "2024-07-23 18:20:13,773 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"langboat/mengzi-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:17.607305Z",
     "iopub.status.busy": "2024-07-23T10:20:17.606942Z",
     "iopub.status.idle": "2024-07-23T10:20:17.610389Z",
     "shell.execute_reply": "2024-07-23T10:20:17.609950Z",
     "shell.execute_reply.started": "2024-07-23T10:20:17.607285Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/.cache/modelscope/langboat/mengzi-t5-base'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:19.938681Z",
     "iopub.status.busy": "2024-07-23T10:20:19.938353Z",
     "iopub.status.idle": "2024-07-23T10:20:20.116483Z",
     "shell.execute_reply": "2024-07-23T10:20:20.115971Z",
     "shell.execute_reply.started": "2024-07-23T10:20:19.938663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:21.936582Z",
     "iopub.status.busy": "2024-07-23T10:20:21.936265Z",
     "iopub.status.idle": "2024-07-23T10:20:21.939753Z",
     "shell.execute_reply": "2024-07-23T10:20:21.939299Z",
     "shell.execute_reply.started": "2024-07-23T10:20:21.936565Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(exmaples):\n",
    "    contents = [\"摘要生成: \\n\" + e for e in exmaples[\"content\"]]\n",
    "    inputs = tokenizer(contents, max_length=384, truncation=True)\n",
    "    labels = tokenizer(text_target=exmaples[\"title\"], max_length=64, truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:23.203512Z",
     "iopub.status.busy": "2024-07-23T10:20:23.203184Z",
     "iopub.status.idle": "2024-07-23T10:20:23.871936Z",
     "shell.execute_reply": "2024-07-23T10:20:23.871481Z",
     "shell.execute_reply.started": "2024-07-23T10:20:23.203493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, batched=True)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:25.619651Z",
     "iopub.status.busy": "2024-07-23T10:20:25.619300Z",
     "iopub.status.idle": "2024-07-23T10:20:25.624540Z",
     "shell.execute_reply": "2024-07-23T10:20:25.624091Z",
     "shell.execute_reply.started": "2024-07-23T10:20:25.619632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'摘要生成: 发布日期:2015-03-3007:55:33郴州市气象台3月30日7时52分发布雷电橙色预警信号:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受雷电活动影响,并将持续,出现雷电灾害事故的可能性比较大,请注意防范。图例标准防御指南2小时内发生雷电活动的可能性很大,或者已经受雷电活动影响,且可能持续,出现雷电灾害事故的可能性比较大。1、政府及相关部门按照职责落实防雷应急措施;2、人员应当留在室内,并关好门窗;3、户外人员应当躲入有防雷设施的建筑物或者汽车内;4、切断危险电源,不要在树下、电杆下、塔吊下避雨;5、在空旷场地不要打伞,不要把农具、羽毛球拍、高尔夫球杆等扛在肩上。</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:28.197649Z",
     "iopub.status.busy": "2024-07-23T10:20:28.197318Z",
     "iopub.status.idle": "2024-07-23T10:20:28.201673Z",
     "shell.execute_reply": "2024-07-23T10:20:28.201198Z",
     "shell.execute_reply.started": "2024-07-23T10:20:28.197630Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'郴州市发布雷电橙色预警:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受...</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_ds[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:29.749012Z",
     "iopub.status.busy": "2024-07-23T10:20:29.748694Z",
     "iopub.status.idle": "2024-07-23T10:20:29.752368Z",
     "shell.execute_reply": "2024-07-23T10:20:29.751863Z",
     "shell.execute_reply.started": "2024-07-23T10:20:29.748994Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 27508, 5045, 1299, 1098, 580, 21296, 7701, 13, 888, 99, 1429, 512, 1080, 159, 6, 1193, 1707, 159, 6, 27508, 5045, 159, 6, 4449, 12817, 6, 2471, 761, 308, 6, 2351, 10099, 308, 6, 2476, 1345, 157, 6, 4449, 301, 308, 6, 7787, 17442, 147, 425, 1542, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_ds[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:32.031890Z",
     "iopub.status.busy": "2024-07-23T10:20:32.031560Z",
     "iopub.status.idle": "2024-07-23T10:20:34.741060Z",
     "shell.execute_reply": "2024-07-23T10:20:34.740489Z",
     "shell.execute_reply.started": "2024-07-23T10:20:32.031871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 创建评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install rouge_chinese transformers==4.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:20:51.792052Z",
     "iopub.status.busy": "2024-07-23T10:20:51.791683Z",
     "iopub.status.idle": "2024-07-23T10:20:52.108492Z",
     "shell.execute_reply": "2024-07-23T10:20:52.107998Z",
     "shell.execute_reply.started": "2024-07-23T10:20:51.792030Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge_chinese import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def compute_metric(evalPred):\n",
    "    def calculate_bleu_scores(candidate, references):\n",
    "        candidate = list(candidate.split(\" \"))\n",
    "        reference = [list(references.split(\" \"))]\n",
    "        weights_list = [\n",
    "            (1, 0, 0, 0),   # BLEU-1\n",
    "            (0.5, 0.5, 0, 0),   # BLEU-2\n",
    "            (1/3, 1/3, 1/3, 0),   # BLEU-3\n",
    "            (0.25, 0.25, 0.25, 0.25) # BLEU-4\n",
    "        ]\n",
    "\n",
    "        bleu_scores = []\n",
    "        for weights in weights_list:\n",
    "            # print(sentence_bleu(reference, candidate, weights=weights))\n",
    "            score = sentence_bleu(reference, candidate, weights=weights)\n",
    "            bleu_scores.append(score)\n",
    "        return bleu_scores\n",
    "    predictions, labels = evalPred\n",
    "    decode_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(l) for l in decode_labels]\n",
    "    rouge_scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    bleu_scores_batch = np.mean(np.array([calculate_bleu_scores(cand, refs) for cand, refs in zip(decode_preds, decode_labels)]), axis=0)\n",
    "    return {\n",
    "        \"rouge-1\": rouge_scores[\"rouge-1\"][\"f\"],\n",
    "        \"rouge-2\": rouge_scores[\"rouge-2\"][\"f\"],\n",
    "        \"rouge-l\": rouge_scores[\"rouge-l\"][\"f\"],\n",
    "        \"bleu-l\": bleu_scores_batch[0],\n",
    "        \"bleu-2\": bleu_scores_batch[1],\n",
    "        \"bleu-3\": bleu_scores_batch[2],\n",
    "        \"bleu-4\": bleu_scores_batch[3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "decode_preds = [\" \".join(p) for p in [\"这是一份行动指南，确保军队始终服从党的命令\", \"确保军队始终服从党的命令\"]]\n",
    "decode_labels = [\" \".join(l) for l in [\"这是一份行动指南，确保军队永远听从党的指挥\", \"确保军队永远听从党的指挥\"]]\n",
    "print(decode_preds, decode_labels)\n",
    "scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "# 定义一个函数来计算所有四个BLEU分数\n",
    "\n",
    "\n",
    "\n",
    "# 使用一个列表推导式来计算batch中每个候选句子的BLEU分数\n",
    "bleu_scores_batch = np.mean(np.array([calculate_bleu_scores(cand, refs) for cand, refs in zip(decode_preds, decode_labels)]), axis=0)\n",
    "bleu_dict = {f'bleu-{i+1}': score for i, score in enumerate(bleu_scores_batch)}\n",
    "bleu_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:24:53.392919Z",
     "iopub.status.busy": "2024-07-23T10:24:53.392566Z",
     "iopub.status.idle": "2024-07-23T10:24:53.397648Z",
     "shell.execute_reply": "2024-07-23T10:24:53.397105Z",
     "shell.execute_reply.started": "2024-07-23T10:24:53.392898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from transformers import Seq2SeqTrainingArguments, TrainerCallback\n",
    "from transformers.trainer_utils import TrainOutput\n",
    "\n",
    "class MetricsLoggerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            loss = logs['loss']\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            self.metrics.append(metrics)\n",
    "\n",
    "# 创建MetricsLoggerCallback实例\n",
    "metrics_logger_callback = MetricsLoggerCallback()\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./model_output',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to='none',  # 避免额外报告，仅使用自定义日志\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(Seq2SeqTrainingArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 创建训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T10:24:54.769776Z",
     "iopub.status.busy": "2024-07-23T10:24:54.769433Z",
     "iopub.status.idle": "2024-07-23T10:24:54.843284Z",
     "shell.execute_reply": "2024-07-23T10:24:54.842640Z",
     "shell.execute_reply.started": "2024-07-23T10:24:54.769757Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'use_seedable_sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataCollatorForSeq2Seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer_seq2seq.py:57\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     model: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, nn\u001b[38;5;241m.\u001b[39mModule] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_logits_for_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:403\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:4604\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4601\u001b[0m     args\u001b[38;5;241m.\u001b[39mupdate(accelerator_config)\n\u001b[1;32m   4603\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 4604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4605\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'use_seedable_sampler'"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "    callbacks=[metrics_logger_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:15:38.342310Z",
     "iopub.status.busy": "2024-07-23T09:15:38.341949Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 38/450 52:14 < 9:57:52, 0.01 it/s, Epoch 0.25/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step9 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\"摘要生成:\\n\" + ds[\"test\"][-1][\"content\"], max_length=64, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"test\"][-1][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
